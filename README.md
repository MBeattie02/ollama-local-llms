# ollama-local-llms

A collection of quickstart examples for working with local LLMs using Ollama.

## Overview

This repository contains simple Python examples demonstrating how to:

- Use Ollama directly with the Python client
- Integrate Ollama with LangChain for more advanced workflows
- Use tool calling with LangChain and Ollama models
